{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 输入图像的维度，此处是mnist图像，因此是28*28\n",
    "img_rows, img_cols = 28, 28\n",
    "# 卷积层中使用的卷积核的个数\n",
    "nb_filters = 32\n",
    "# 池化层操作的范围\n",
    "pool_size = (2,2)\n",
    "# 卷积核的大小\n",
    "kernel_size = (3,3)\n",
    "# keras中的mnist数据集已经被划分成了60,000个训练集，10,000个测试集的形式，按以下格式调用即可\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 后端使用tensorflow时，即tf模式下，\n",
    "# 会将100张RGB三通道的16*32彩色图表示为(100,16,32,3)，\n",
    "# 第一个维度是样本维，表示样本的数目，\n",
    "# 第二和第三个维度是高和宽，\n",
    "# 最后一个维度是通道维，表示颜色通道数\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "# plt.imshow(X_train[0].reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 将X_train, X_test的数据格式转为float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# 归一化\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# 打印出相关信息\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将类别向量(从0到nb_classes的整数向量)映射为二值类别矩阵，\n",
    "# 相当于将向量用one-hot重新编码\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qzx/env/py3.5/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., padding=\"valid\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/qzx/env/py3.5/lib/python3.5/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立序贯模型\n",
    "model = Sequential()\n",
    "\n",
    "# 卷积层，对二维输入进行滑动窗卷积\n",
    "# 当使用该层为第一层时，应提供input_shape参数，在tf模式中，通道维位于第三个位置\n",
    "# border_mode：边界模式，为\"valid\",\"same\"或\"full\"，即图像外的边缘点是补0\n",
    "# 还是补成相同像素，或者是补1\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0] ,kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 卷积层，激活函数是ReLu\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 池化层，选用Maxpooling，给定pool_size，dropout比例为0.25\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten层，把多维输入进行一维化，常用在卷积层到全连接层的过渡\n",
    "model.add(Flatten())\n",
    "\n",
    "# 包含128个神经元的全连接层，激活函数为ReLu，dropout比例为0.5\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 包含10个神经元的输出层，激活函数为Softmax\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 输出模型的参数信息\n",
    "model.summary()\n",
    "# 配置模型的学习过程\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qzx/env/py3.5/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0389 - acc: 0.9881 - val_loss: 0.0382 - val_acc: 0.9892\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0387 - acc: 0.9884 - val_loss: 0.0304 - val_acc: 0.9906\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0387 - acc: 0.9883 - val_loss: 0.0293 - val_acc: 0.9907\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0341 - acc: 0.9901 - val_loss: 0.0355 - val_acc: 0.9912\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0340 - acc: 0.9903 - val_loss: 0.0297 - val_acc: 0.9914\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.0355 - acc: 0.9898 - val_loss: 0.0323 - val_acc: 0.9916\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0348 - acc: 0.9900 - val_loss: 0.0385 - val_acc: 0.9907\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0364 - acc: 0.9899 - val_loss: 0.0352 - val_acc: 0.9911\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.0372 - acc: 0.9898 - val_loss: 0.0316 - val_acc: 0.9915\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.0356 - acc: 0.9901 - val_loss: 0.0406 - val_acc: 0.9906\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0343 - acc: 0.9905 - val_loss: 0.0365 - val_acc: 0.9917\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0353 - acc: 0.9897 - val_loss: 0.0353 - val_acc: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "model.save('1.h5')\n",
    "# 按batch计算在某些输入数据上模型的误差\n",
    "# score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.035283134788431744, 0.9915]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('1.h5')\n",
    "classes = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'IplImage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5edff2214734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.load_weights('1.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mIplImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/timg.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'IplImage'"
     ]
    }
   ],
   "source": [
    "# model.load_weights('1.h5')\n",
    "import cv2\n",
    "img = cv2.imread('images/timg.jpeg')\n",
    "\n",
    "img = cv2.resize(img, (28,28), interpolation=cv2.INTER_CUBIC)\n",
    "print(merged.shape)\n",
    "# img_class = model.predict_classes(res)\n",
    "# print(img_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IplImage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cf9e33a337bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIplImage\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvLoadImage\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"images/timg.jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(src.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IplImage' is not defined"
     ]
    }
   ],
   "source": [
    "import IplImage\n",
    "IplImage* src\n",
    "src = cvLoadImage( \"images/timg.jpeg\", 0)\n",
    "# print(src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
